import os
import time
from datetime import timedelta
import argparse
import pickle

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset, random_split
import pandas as pd
import numpy as np
import matplotlib

matplotlib.use('Agg')
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
from tqdm import tqdm

from models.multi_token_dual_attention import MultiTokenDualOutputPhysicsInformedAttentionNet
from utils.attention_viz import (
    visualize_attention_weights,
    compute_average_attention_weights,
    visualize_average_attention_weights,
)


def resolve_first_existing(candidates):
    for p in candidates:
        if os.path.exists(p):
            return p
    return candidates[0]


def main():
    parser = argparse.ArgumentParser(description='Multi-Token Dual-Output Training & Visualization')
    parser.add_argument('--te_csv', type=str, default=os.path.join('data', 'TE.csv'), help='Path to TE CSV file')
    parser.add_argument('--tm_csv', type=str, default=os.path.join('data', 'TM.csv'), help='Path to TM CSV file')
    parser.add_argument('--fig_dir', type=str, default='fig', help='Directory to save figures')
    parser.add_argument('--epochs', type=int, default=200, help='Total training epochs')
    parser.add_argument('--batch_size', type=int, default=128, help='Batch size')
    parser.add_argument('--lr', type=float, default=1e-3, help='Learning rate')
    parser.add_argument('--weight_decay', type=float, default=1e-5, help='Weight decay')
    args = parser.parse_args()

    plt.rcParams['font.family'] = ['Times New Roman']
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['figure.dpi'] = 300
    plt.rcParams['savefig.dpi'] = 300
    plt.rcParams['savefig.bbox'] = 'tight'
    plt.rcParams['savefig.pad_inches'] = 0.1

    fig_save_path = args.fig_dir
    os.makedirs(fig_save_path, exist_ok=True)

    print('1. Preparing data...')
    file_path_te = resolve_first_existing([
        args.te_csv,
        r'C:\\Users\\windows\\Desktop\\data\\新三层矩形光栅\\TE.csv',
    ])
    file_path_tm = resolve_first_existing([
        args.tm_csv,
        r'C:\\Users\\windows\\Desktop\\data\\新三层矩形光栅\\TM.csv',
    ])

    print('Reading TE-mode data...')
    df_te = pd.read_csv(file_path_te, encoding_errors='ignore')
    print(f'TE data shape: {df_te.shape}')
    print(f'TE data columns: {df_te.columns.tolist()}')

    print('Reading TM-mode data...')
    df_tm = pd.read_csv(file_path_tm, encoding_errors='ignore')
    print(f'TM data shape: {df_tm.shape}')
    print(f'TM data columns: {df_tm.columns.tolist()}')

    if df_te.shape[0] != df_tm.shape[0]:
        raise ValueError(f'Mismatched number of rows between TE and TM: {df_te.shape[0]} vs {df_tm.shape[0]}')

    X = df_te.iloc[:, :4].values
    y_te = df_te.iloc[:, 4].values.reshape(-1, 1)
    y_tm = df_tm.iloc[:, 4].values.reshape(-1, 1)
    y = np.column_stack([y_te.flatten(), y_tm.flatten()])

    scaler_X = StandardScaler()
    X = scaler_X.fit_transform(X)

    X_tensor = torch.tensor(X, dtype=torch.float32)
    y_tensor = torch.tensor(y, dtype=torch.float32)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f'Using device: {device}')

    dataset = TensorDataset(X_tensor, y_tensor)
    train_ratio = 0.6
    train_size = int(train_ratio * len(X_tensor))
    test_size = len(X_tensor) - train_size
    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])
    X_train, y_train = train_dataset[:][0].to(device), train_dataset[:][1].to(device)
    X_test, y_test = test_dataset[:][0].to(device), test_dataset[:][1].to(device)

    print('Dataset split:')
    print(f'  Total samples: {len(X_tensor)}')
    print(f'  Train ratio: {train_ratio:.1f} ({train_size} samples)')
    print(f'  Test ratio: {1 - train_ratio:.1f} ({test_size} samples)')
    print(f'  Train/Test split: {train_size}/{test_size}')

    print('\n2. Initializing multi-token dual-output model...')
    model = MultiTokenDualOutputPhysicsInformedAttentionNet(
        input_dim=X_train.shape[1],
        d_model=128,
        num_heads=2,
        num_layers=1,
    ).to(device)

    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")

    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)

    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=args.batch_size, shuffle=True)

    print("\n3. Start training multi-token model (overall progress)...")
    train_losses, val_losses = [], []
    sampled_train_losses, sampled_val_losses = [], []
    sampled_success_rates_005, sampled_success_rates_01 = [], []
    sampled_r2_scores, sampled_r2_scores_te, sampled_r2_scores_tm = [], [], []
    sampled_epochs = []
    delta, delta2 = 0.05, 0.1

    total_epochs = args.epochs
    total_steps = total_epochs * len(train_loader)
    start_time = time.time()
    best_loss = float('inf')

    progress_bar = tqdm(total=total_steps, desc="Multi-Token Training", unit="batch")
    for epoch in range(total_epochs):
        model.train()
        epoch_loss = 0.0

        for X_batch, y_batch in train_loader:
            optimizer.zero_grad()
            outputs = model(X_batch)
            loss = criterion(outputs, y_batch)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

            elapsed = time.time() - start_time
            steps_completed = epoch * len(train_loader) + 1
            samples_processed = steps_completed * train_loader.batch_size
            samples_per_sec = samples_processed / elapsed if elapsed > 0 else 0
            progress_bar.update(1)
            progress_bar.set_postfix({
                'Epoch': f'{epoch + 1}/{total_epochs}',
                'Loss': f'{loss.item():.4f}',
                'Samples/sec': f'{samples_per_sec:.1f}',
                'Elapsed': str(timedelta(seconds=int(elapsed)))
            })

        avg_train_loss = epoch_loss / len(train_loader)
        train_losses.append(avg_train_loss)

        model.eval()
        with torch.no_grad():
            val_outputs = model(X_test)
            val_loss = criterion(val_outputs, y_test).item()
            val_losses.append(val_loss)

        scheduler.step(val_loss)

        if val_loss < best_loss:
            best_loss = val_loss
            torch.save(model.state_dict(), 'best_multi_token_model.pth')

        # Sample every 5 epochs for plotting
        if (epoch + 1) % 5 == 0:
            with torch.no_grad():
                val_predictions = model(X_test).cpu().numpy()
                val_true = y_test.cpu().numpy()

                sampled_train_losses.append(avg_train_loss)
                sampled_val_losses.append(val_loss)
                sampled_epochs.append(epoch + 1)

                success_mask_005 = np.all(np.abs(val_predictions - val_true) < delta, axis=1)
                sampled_success_rates_005.append(np.mean(success_mask_005) * 100)

                success_mask_01 = np.all(np.abs(val_predictions - val_true) < delta2, axis=1)
                sampled_success_rates_01.append(np.mean(success_mask_01) * 100)

                r2_overall = r2_score(val_true, val_predictions)
                r2_te = r2_score(val_true[:, 0], val_predictions[:, 0])
                r2_tm = r2_score(val_true[:, 1], val_predictions[:, 1])
                sampled_r2_scores.extend([r2_overall])
                sampled_r2_scores_te.extend([r2_te])
                sampled_r2_scores_tm.extend([r2_tm])

    progress_bar.close()

    # Save scaler
    with open('scaler_X_multi_token.pkl', 'wb') as f:
        pickle.dump(scaler_X, f)
    print('Multi-token input scaler saved to scaler_X_multi_token.pkl')

    # Plot curves using sampled points
    def _plot_curve(x, ys, labels, title, y_label, fname):
        fig, ax = plt.subplots(1, 1, figsize=(12, 8))
        colors = ['#2E86AB', '#A23B72', '#9B59B6']
        markers = ['o-', 's-', 'd-']
        for i, y in enumerate(ys):
            if y:
                ax.plot(x, y, markers[i], color=colors[i], linewidth=2, markersize=6, label=labels[i], alpha=0.8)
        ax.set_xlabel('Epoch', fontsize=32, fontweight='bold', fontfamily='Times New Roman')
        ax.set_ylabel(y_label, fontsize=32, fontweight='bold', fontfamily='Times New Roman')
        ax.set_title(title, fontsize=26, fontweight='bold', fontfamily='Times New Roman', pad=15)
        ax.legend(frameon=False, fancybox=True, shadow=False, prop={'family': 'Times New Roman', 'size': 20})
        ax.grid(True, alpha=0.3, linestyle='--')
        ax.tick_params(axis='both', which='major', labelsize=28)
        for label in ax.get_xticklabels() + ax.get_yticklabels():
            label.set_fontweight('bold')
        for k in ['top', 'bottom', 'left', 'right']:
            ax.spines[k].set_linewidth(2)
        plt.tight_layout()
        plt.savefig(os.path.join(fig_save_path, f'{fname}.pdf'), format='pdf', bbox_inches='tight', pad_inches=0.1)
        plt.savefig(os.path.join(fig_save_path, f'{fname}.png'), format='png', bbox_inches='tight', pad_inches=0.1)
        plt.close()

    _plot_curve(sampled_epochs, [sampled_train_losses, sampled_val_losses],
                ['Training Loss', 'Validation Loss'],
                'Multi-Token Training and Validation Loss', 'Loss', 'multi_token_loss_curve')

    _plot_curve(sampled_epochs, [sampled_success_rates_005, sampled_success_rates_01],
                [f'Success Rate (δ={0.05})', f'Success Rate (δ={0.1})'],
                'Multi-Token Success Rate Progress (Multiple Thresholds)', 'Success Rate (%)',
                'multi_token_success_rate')

    _plot_curve(sampled_epochs, [sampled_r2_scores_te, sampled_r2_scores_tm, sampled_r2_scores],
                ['TE Mode R² Score', 'TM Mode R² Score', 'Overall R² Score'],
                'Multi-Token R² Score Progress (TE, TM & Overall)', 'R² Score', 'multi_token_r2_score')

    print(f'Figures saved to: {fig_save_path}')
    print('  • multi_token_loss_curve.pdf/.png - Loss curves')
    print('  • multi_token_success_rate.pdf/.png - Success rate curves')
    print('  • multi_token_r2_score.pdf/.png - R² curves')

    # Attention visualization
    print("\n6. Visualizing attention weights...")
    visualize_attention_weights(model, X_test, y_test, scaler_X, fig_save_path, num_samples=3)

    print("\n7. Computing average attention over samples...")
    results, param_names, used_samples = compute_average_attention_weights(model, X_test, max_samples=5000)
    visualize_average_attention_weights(results, param_names, used_samples, fig_save_path)

    # Final metrics with best model
    print("\n8. Computing final performance metrics...")
    model.load_state_dict(torch.load('best_multi_token_model.pth', map_location=device))
    model.eval()
    with torch.no_grad():
        final_predictions = model(X_test).cpu().numpy()
        final_true = y_test.cpu().numpy()

    final_mse = np.mean((final_predictions - final_true) ** 2)
    final_r2_overall = r2_score(final_true, final_predictions)
    final_r2_te = r2_score(final_true[:, 0], final_predictions[:, 0])
    final_r2_tm = r2_score(final_true[:, 1], final_predictions[:, 1])

    delta1, delta2 = 0.05, 0.1
    success_mask_005 = np.all(np.abs(final_predictions - final_true) < delta1, axis=1)
    final_success_rate_005 = np.mean(success_mask_005) * 100
    success_mask_01 = np.all(np.abs(final_predictions - final_true) < delta2, axis=1)
    final_success_rate_01 = np.mean(success_mask_01) * 100

    print("\n" + "=" * 60)
    print("Final performance (Multi-Token model)")
    print("=" * 60)
    print(f"Test size: {len(final_true):,} samples")
    print(f"Final MSE: {final_mse:.6f}")
    print(f"Final R² (overall): {final_r2_overall:.6f}")
    print(f"Final R² (TE): {final_r2_te:.6f}")
    print(f"Final R² (TM): {final_r2_tm:.6f}")
    print(f"Success rate (δ={delta1}): {final_success_rate_005:.2f}%")
    print(f"Success rate (δ={delta2}): {final_success_rate_01:.2f}%")
    print("=" * 60)

    te_mae = np.mean(np.abs(final_predictions[:, 0] - final_true[:, 0]))
    tm_mae = np.mean(np.abs(final_predictions[:, 1] - final_true[:, 1]))
    overall_mae = np.mean(np.abs(final_predictions - final_true))
    te_mse = np.mean((final_predictions[:, 0] - final_true[:, 0]) ** 2)
    tm_mse = np.mean((final_predictions[:, 1] - final_true[:, 1]) ** 2)

    print("Mean Absolute Error (MAE):")
    print(f"   • Overall MAE: {overall_mae:.6f}")
    print(f"   • TE MAE: {te_mae:.6f}")
    print(f"   • TM MAE: {tm_mae:.6f}")
    print("Mean Squared Error (MSE) breakdown:")
    print(f"   • Overall MSE: {final_mse:.6f}")
    print(f"   • TE MSE: {te_mse:.6f}")
    print(f"   • TM MSE: {tm_mse:.6f}")

    print("\nTraining complete!")
    print("Model trained and saved successfully")
    print("Generated training loss curves, attention visualizations, and average attention statistics")
    print(f"All figures saved to: {fig_save_path}")


if __name__ == '__main__':
    main()
